{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27d4e493"
      },
      "source": [
        "# Customer Churn Prediction\n",
        "\n",
        "\n",
        "## Problem Definition\n",
        "**Customer Churn** refers to customers who stop using a company's product or service.  \n",
        "The goal is to **predict which customers are likely to churn** based on historical behavior.\n",
        "\n",
        "\n",
        "## Why This Problem is Important\n",
        "- Retaining existing customers is **cheaper than acquiring new ones**.  \n",
        "- Helps companies **increase revenue and improve customer satisfaction**.  \n",
        "- Enables **targeted retention strategies** for at-risk customers.\n",
        "\n",
        "\n",
        "##  How Machine Learning Can Help\n",
        "- ML models can **analyze historical customer data** to detect churn patterns.  \n",
        "- **Predictive models** identify high-risk customers **before they leave**.  \n",
        "- Supports **data-driven decision making** in marketing and customer support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHIfVzlDFpCL"
      },
      "outputs": [],
      "source": [
        "# Very basic data science imports\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "# Scaling,Imbalance Handling,cross val,encoding,Classification metrics,pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "# Model Imports\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXsUQLPFW5i3"
      },
      "source": [
        "Uploading datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMkDT_-YHMXF"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Customer churn/Train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Customer churn/Test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45VxYFHAHZu5"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtKw8PMlHc37"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Z2XDju0HgUk"
      },
      "outputs": [],
      "source": [
        "train.drop('CustomerID', axis=1, inplace=True)\n",
        "test.drop('CustomerID', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5b8ra_ATMwS"
      },
      "outputs": [],
      "source": [
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "found one row of nulls in every column so I just dropped it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHtmOZIEatIk"
      },
      "outputs": [],
      "source": [
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQy9IZPTWLm3"
      },
      "outputs": [],
      "source": [
        "train.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiD8blsBWSCL"
      },
      "outputs": [],
      "source": [
        "print(train.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBAi9hBIazyi"
      },
      "outputs": [],
      "source": [
        "print(test.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9neMqpT0Yvug"
      },
      "outputs": [],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z7kjepaH3Ds"
      },
      "outputs": [],
      "source": [
        "train.describe(include= 'object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPs-nIfPH638"
      },
      "outputs": [],
      "source": [
        "train_num_col = train.select_dtypes(include='number').columns\n",
        "train_cat_col = train.select_dtypes(include='object').columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3aa5u-GfjBD"
      },
      "outputs": [],
      "source": [
        "test_num_col = test.select_dtypes(include='number').columns\n",
        "test_cat_col = test.select_dtypes(include='object').columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8vF8G0NYcoT"
      },
      "source": [
        "**Dataset Summary**\n",
        "\n",
        "Numerical columns (8): CustomerID, Age, Tenure, Usage Frequency, Support Calls, Payment Delay, Total Spend, Last Interaction\n",
        "\n",
        "Binary nominal column (1): Gender\n",
        "\n",
        "Ordinal categorical columns (2): Contract Length, Subscription Type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9FkR5NaZEdU"
      },
      "source": [
        "**Outlier Detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3X2hpQAIUjI"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.boxplot(data=train[train_num_col] , palette='Greens')\n",
        "\n",
        "plt.title('Boxplot for Outlier Detection')\n",
        "plt.xticks(rotation = 45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzRXSsStZTli"
      },
      "source": [
        "As we see above there are no outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID6kI2U4IVKj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "\n",
        "sns.countplot(\n",
        "    data=train,\n",
        "    x=\"Churn\" ,width =.4\n",
        ")\n",
        "\n",
        "plt.title(\"Churn Distribution\")\n",
        "plt.xlabel(\"Churn\")\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "022V-nEOZd3E"
      },
      "source": [
        "The plot above reveals a significant class imbalance.\n",
        "\n",
        "** Class 0 (Retained) represents the majority, while Class 1 (Churned) is the minority.\n",
        "\n",
        "To address this issue we can use techniques like Undersampling or SMOTE to prevent the model from becoming biased toward the majority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjlrICllLeQL"
      },
      "outputs": [],
      "source": [
        "n_cols = len(train_num_col)\n",
        "n_rows = (n_cols + 3) // 4\n",
        "\n",
        "plt.figure(figsize=(15, 4 * n_rows))\n",
        "\n",
        "for i, col in enumerate(train_num_col, 1):\n",
        "    plt.subplot(n_rows, 4, i)\n",
        "    sns.histplot(data=train, x=col, kde=True, bins=30, color='skyblue')\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rwi_82OcXPe"
      },
      "source": [
        "\n",
        "As we can see in above plot, none of the numerical features are in a normal distribution. This is acceptable as we are primarily using tree-based models (Decision Tree, Random Forest, XGBoost), which are non-parametric and do not assume any specific data distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IprPdVRLjYZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i, col in enumerate(train_cat_col, 1):\n",
        "    plt.subplot(1 , 3 , i)\n",
        "    sns.countplot(data=train, x=col , hue = 'Churn' , palette=\"Greens\")\n",
        "    plt.title(f'Distribution of {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6c45eeb"
      },
      "source": [
        "- We observed that females have a higher churn rate than males.\n",
        "- Customers with monthly contracts have the highest churn rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WSh4RJgNtJq"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data=train, x='Churn', y='Tenure', palette=\"Blues\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49caayMeNvXb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "corr = train[train_num_col].corr()\n",
        "corr_with_target = corr['Churn'].sort_values(ascending= True).to_frame()\n",
        "sns.heatmap(\n",
        "    data=corr_with_target,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"Blues\",\n",
        "    cbar=True,\n",
        "    linewidths=0.5,\n",
        "    linecolor='white',\n",
        "    square=True\n",
        ")\n",
        "\n",
        "plt.title(\"Correlation  With Target\", fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy4EThWbfj5b"
      },
      "source": [
        "Feature correlation with the target variable (Churn). Support Calls shows the strongest positive correlation (0.52).\n",
        "\n",
        "Note: A full correlation matrix was analyzed, and no significant multicollinearity was found between independent features, validating the use of linear models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BYfzwa6NwFU"
      },
      "outputs": [],
      "source": [
        "X_train = train.drop('Churn', axis=1)\n",
        "y_train = train['Churn']\n",
        "\n",
        "X_test = test.drop('Churn', axis=1)\n",
        "y_test = test['Churn']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6LWobcF01lT"
      },
      "outputs": [],
      "source": [
        "print(\"\\nStarting Modeling Phase...\\n\")\n",
        "numeric_features = ['Age', 'Tenure', 'Usage Frequency', 'Support Calls',\n",
        "                    'Payment Delay', 'Total Spend', 'Last Interaction']\n",
        "ordinal_features = ['Subscription Type', 'Contract Length']\n",
        "nominal_features = ['Gender']\n",
        "print(\"Numeric:\", numeric_features)\n",
        "print(\"Ordinal:\", ordinal_features)\n",
        "print(\"Nominal:\", nominal_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R6SuRAITITZ"
      },
      "outputs": [],
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat_nom', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), nominal_features),\n",
        "        ('cat_ord', OrdinalEncoder(categories=[\n",
        "            ['Basic', 'Standard', 'Premium'],\n",
        "            ['Monthly', 'Quarterly', 'Annual']\n",
        "        ]), ordinal_features)\n",
        "    ],\n",
        "    remainder='drop',\n",
        "    verbose_feature_names_out=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gnxfUJGTLZH"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(solver='lbfgs', max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        device=\"cpu\",\n",
        "        tree_method=\"hist\"\n",
        "    )\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"classifier__C\": [0.01, 0.1, 1, 10]\n",
        "    },\n",
        "    \"Decision Tree\": {\n",
        "        \"classifier__max_depth\": [3, 5, 10, None],\n",
        "        \"classifier__min_samples_split\": [2, 5, 10]\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        \"classifier__n_estimators\": [50, 100, 150],\n",
        "        \"classifier__max_depth\": [3, 5, 10, None]\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"classifier__n_estimators\": [50, 100, 150],\n",
        "        \"classifier__learning_rate\": [0.01, 0.1, 0.2],\n",
        "        \"classifier__max_depth\": [3, 5, 7]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8KkyM0MTpF5"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "#looping through every model\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    if name in param_grids:\n",
        "\n",
        "        grid = GridSearchCV(\n",
        "            pipeline,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='accuracy',\n",
        "            cv=3,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        grid.fit(X_train, y_train)\n",
        "        best_model = grid.best_estimator_\n",
        "        best_params = grid.best_params_\n",
        "    else:\n",
        "        best_model = pipeline.fit(X_train, y_train)\n",
        "        best_params = \"Default\"\n",
        "\n",
        "    #  Predict & Evaluate\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = round(accuracy_score(y_test, y_pred), 2)\n",
        "    prec = round(precision_score(y_test, y_pred), 2)\n",
        "    rec = round(recall_score(y_test, y_pred), 2)\n",
        "    f1 = round(f1_score(y_test, y_pred), 2)\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1-score\": f1,\n",
        "        \"Best Params\": best_params\n",
        "    })\n",
        "\n",
        "    print(f\"--- {name} Results ---\")\n",
        "    print(f\"Accuracy: {acc} | F1: {f1}\")\n",
        "\n",
        "# Display final comparison table\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Model Comparison:\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ1U6An9Tp5Q"
      },
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-DUxVCGcO-A"
      },
      "outputs": [],
      "source": [
        "results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": round(accuracy_score(y_test, y_pred), 2),\n",
        "        \"Precision\": round(precision_score(y_test, y_pred), 2),\n",
        "        \"Recall\": round(recall_score(y_test, y_pred), 2),\n",
        "        \"F1-score\": round(f1_score(y_test, y_pred), 2),\n",
        "        \"Best Params\": best_params\n",
        "    })\n",
        "\n",
        "print(f\"\\n--- {name} Results ---\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Model Comparison:\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8EA_dywK8Gi"
      },
      "outputs": [],
      "source": [
        "correlations = train.corr(numeric_only=True)['Churn'].sort_values()\n",
        "\n",
        "print(\"Top Positive Correlations:\\n\", correlations.tail(5))\n",
        "print(\"Top Negative Correlations:\\n\", correlations.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQjjReWIjQt3"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "preprocessor_step = best_model.named_steps['preprocessor']\n",
        "\n",
        "xgboost_step = best_model.named_steps['classifier']\n",
        "\n",
        "X_test_transformed = preprocessor_step.transform(X_test)\n",
        "\n",
        "feature_names = (\n",
        "    preprocessor_step.named_transformers_['num'].get_feature_names_out().tolist() +\n",
        "    preprocessor_step.named_transformers_['cat_nom'].get_feature_names_out().tolist() +\n",
        "    preprocessor_step.named_transformers_['cat_ord'].get_feature_names_out().tolist()\n",
        ")\n",
        "\n",
        "explainer = shap.TreeExplainer(xgboost_step)\n",
        "shap_values = explainer.shap_values(X_test_transformed)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_names, show=False)\n",
        "plt.title(\"SHAP Summary Plot (Feature Impact on Churn)\", fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fczlOHcUhUCF"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Customer churn'\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "file_path = os.path.join(folder_path, 'Best_Model.pkl')\n",
        "joblib.dump(best_model, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gzfe2wxJkluB"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login, HfApi\n",
        "\n",
        "login(token=\"HF TOKEN\")\n",
        "api = HfApi()\n",
        "\n",
        "model_repo = \"MY REPO LINK\"\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/drive/MyDrive/Customer churn/Best_Model.pkl\",\n",
        "    path_in_repo=\"Best_Model.pkl\",\n",
        "    repo_id=model_repo,\n",
        "    repo_type=\"model\"\n",
        ")\n",
        "\n",
        "dataset_repo = \"MY DATA SET REPO\"\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/drive/MyDrive/Customer churn/Train.csv\",\n",
        "    path_in_repo=\"Train.csv\",\n",
        "    repo_id=dataset_repo,\n",
        "    repo_type=\"dataset\"\n",
        ")\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/drive/MyDrive/Customer churn/Test.csv\",\n",
        "    path_in_repo=\"Test.csv\",\n",
        "    repo_id=dataset_repo,\n",
        "    repo_type=\"dataset\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
