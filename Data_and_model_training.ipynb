{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHIfVzlDFpCL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMkDT_-YHMXF"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Customer churn/Train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Customer churn/Test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45VxYFHAHZu5"
      },
      "outputs": [],
      "source": [
        "print(f\"Train Shape : {train.shape}\")\n",
        "print(f\"Test Shape : {test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtKw8PMlHc37"
      },
      "outputs": [],
      "source": [
        "# Concat Two DataFrames\n",
        "df = pd.concat([train , test] , axis = 0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Z2XDju0HgUk"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJVr3VyRHiu_"
      },
      "outputs": [],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MKXdHlLHmU7"
      },
      "outputs": [],
      "source": [
        "df.drop('CustomerID' , axis = 1 , inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L5FQVYaHqCr"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zxx8BLMuH2ZN"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z7kjepaH3Ds"
      },
      "outputs": [],
      "source": [
        "df.describe(include= 'object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPs-nIfPH638"
      },
      "outputs": [],
      "source": [
        "for col in df.columns :\n",
        "    print(col)\n",
        "    print(df[col].unique())\n",
        "    print(\"*******************\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWMIBsSfH-z1"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVhkFDh6ID1o"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCRK6lCiIHY0"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmTXrQLWIKUr"
      },
      "outputs": [],
      "source": [
        "num_col = df.select_dtypes(include='number').columns\n",
        "cat_col = df.select_dtypes(include='object').columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3X2hpQAIUjI"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.boxplot(data=df[num_col] , palette='Greens')\n",
        "\n",
        "plt.title('Boxplot for Outlier Detection')\n",
        "plt.xticks(rotation = 45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID6kI2U4IVKj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "\n",
        "sns.countplot(\n",
        "    data=df,\n",
        "    x=\"Churn\" ,width =.4\n",
        ")\n",
        "\n",
        "plt.title(\"Churn Distribution\")\n",
        "plt.xlabel(\"Churn\")\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjlrICllLeQL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, col in enumerate(num_col, 1):\n",
        "    plt.subplot(2 , 4, i)\n",
        "    sns.histplot(data=df, x=col, kde=True, bins=30 ,palette='Blues')\n",
        "    plt.title(f'Distribution of {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IprPdVRLjYZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i, col in enumerate(cat_col, 1):\n",
        "    plt.subplot(1 , 3 , i)\n",
        "    sns.countplot(data=df, x=col , hue = 'Churn' , palette=\"Greens\")\n",
        "    plt.title(f'Distribution of {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WSh4RJgNtJq"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data=df, x='Churn', y='Tenure', palette=\"Blues\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49caayMeNvXb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "corr = df[num_col].corr()\n",
        "corr_with_target = corr['Churn'].sort_values(ascending= True).to_frame()\n",
        "sns.heatmap(\n",
        "    data=corr_with_target,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"Blues\",\n",
        "    cbar=True,\n",
        "    linewidths=0.5,\n",
        "    linecolor='white',\n",
        "    square=True\n",
        ")\n",
        "\n",
        "plt.title(\"Correlation  With Target\", fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BYfzwa6NwFU"
      },
      "outputs": [],
      "source": [
        "print(\"\\nStarting Modeling Phase...\\n\")\n",
        "\n",
        "# 1. Define Feature Groups for the Pipeline\n",
        "# (We define these explicitly to ensure the Pipeline maps them correctly)\n",
        "numeric_features = ['Age', 'Tenure', 'Usage Frequency', 'Support Calls',\n",
        "                    'Payment Delay', 'Total Spend', 'Last Interaction']\n",
        "ordinal_features = ['Subscription Type', 'Contract Length']\n",
        "nominal_features = ['Gender']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckebsj7vTFnc"
      },
      "outputs": [],
      "source": [
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R6SuRAITITZ"
      },
      "outputs": [],
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat_nom', OneHotEncoder(drop='first', sparse_output=False), nominal_features),\n",
        "        ('cat_ord', OrdinalEncoder(categories=[\n",
        "            ['Basic', 'Standard', 'Premium'],   # Subscription Order\n",
        "            ['Monthly', 'Quarterly', 'Annual']  # Contract Order\n",
        "        ]), ordinal_features)\n",
        "    ],\n",
        "    verbose_feature_names_out=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gnxfUJGTLZH"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(solver='lbfgs', max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        device=\"cuda\",          # This tells XGBoost to use the GPU\n",
        "        tree_method=\"hist\"      # This is the optimized algorithm for GPU\n",
        "    )\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"classifier__C\": [0.01, 0.1, 1, 10]\n",
        "    },\n",
        "    \"Decision Tree\": {\n",
        "        \"classifier__max_depth\": [3, 5, 10, None],\n",
        "        \"classifier__min_samples_split\": [2, 5, 10]\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        \"classifier__n_estimators\": [50, 100, 150],\n",
        "        \"classifier__max_depth\": [3, 5, 10, None]\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"classifier__n_estimators\": [50, 100, 150],\n",
        "        \"classifier__learning_rate\": [0.01, 0.1, 0.2],\n",
        "        \"classifier__max_depth\": [3, 5, 7]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8KkyM0MTpF5"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Pipeline: Preprocess -> Undersample -> Model\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('sampler', RandomUnderSampler(random_state=42)),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    if name in param_grids:\n",
        "        grid = GridSearchCV(\n",
        "            pipeline,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1',\n",
        "            cv=3,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        grid.fit(X_train, y_train)\n",
        "        best_model = grid.best_estimator_\n",
        "        best_params = grid.best_params_\n",
        "    else:\n",
        "        best_model = pipeline.fit(X_train, y_train)\n",
        "        best_params = \"Default\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ1U6An9Tp5Q"
      },
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-DUxVCGcO-A"
      },
      "outputs": [],
      "source": [
        "# Convert the results list to a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Sort by F1-score (descending) so the best model is at the top\n",
        "results_df = results_df.sort_values(by=\"F1-score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Display the table\n",
        "print(\"Final Model Evaluation Summary:\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQjjReWIjQt3"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "preprocessor_step = best_model.named_steps['preprocessor']\n",
        "\n",
        "xgboost_step = best_model.named_steps['classifier']\n",
        "\n",
        "X_test_transformed = preprocessor_step.transform(X_test)\n",
        "\n",
        "feature_names = (\n",
        "    preprocessor_step.named_transformers_['num'].get_feature_names_out().tolist() +\n",
        "    preprocessor_step.named_transformers_['cat_nom'].get_feature_names_out().tolist() +\n",
        "    preprocessor_step.named_transformers_['cat_ord'].get_feature_names_out().tolist()\n",
        ")\n",
        "\n",
        "explainer = shap.TreeExplainer(xgboost_step)\n",
        "shap_values = explainer.shap_values(X_test_transformed)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_names, show=False)\n",
        "plt.title(\"SHAP Summary Plot (Feature Impact on Churn)\", fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fczlOHcUhUCF"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Customer churn'\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "file_path = os.path.join(folder_path, 'Best_Model.pkl')\n",
        "joblib.dump(best_model, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gzfe2wxJkluB"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login, HfApi\n",
        "\n",
        "login(token=\"TOKEN for HF\")\n",
        "api = HfApi()\n",
        "\n",
        "model_repo = \"Ravichandrachilde/Churn-with-SHAP\"\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/drive/MyDrive/Customer churn/Best_Model.pkl\",\n",
        "    path_in_repo=\"Best_Model.pkl\",\n",
        "    repo_id=model_repo,\n",
        "    repo_type=\"model\"\n",
        ")\n",
        "\n",
        "dataset_repo = \"Ravichandrachilde/Churn\"\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/drive/MyDrive/Customer churn/Train.csv\",\n",
        "    path_in_repo=\"Train.csv\",\n",
        "    repo_id=dataset_repo,\n",
        "    repo_type=\"dataset\"\n",
        ")\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/drive/MyDrive/Customer churn/Test.csv\",\n",
        "    path_in_repo=\"Test.csv\",\n",
        "    repo_id=dataset_repo,\n",
        "    repo_type=\"dataset\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62T8WA66dclh"
      },
      "outputs": [],
      "source": [
        "# 1. Get the fitted preprocessor from inside the pipeline\n",
        "# 'best_model' is the last model trained (XGBoost)\n",
        "fitted_preprocessor = best_model.named_steps['preprocessor']\n",
        "\n",
        "# 2. Extract feature names from that FITTED preprocessor\n",
        "feature_names = (\n",
        "    fitted_preprocessor.named_transformers_['num'].get_feature_names_out().tolist() +\n",
        "    fitted_preprocessor.named_transformers_['cat_nom'].get_feature_names_out().tolist() +\n",
        "    fitted_preprocessor.named_transformers_['cat_ord'].get_feature_names_out().tolist()\n",
        ")\n",
        "\n",
        "# 3. Extract importance from the classifier step\n",
        "importances = best_model.named_steps['classifier'].feature_importances_\n",
        "\n",
        "# 4. Create DataFrame and Plot\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('XGBoost Feature Importance')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
